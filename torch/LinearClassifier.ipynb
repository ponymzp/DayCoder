{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 线性分类\n",
    "\n",
    "在使用 PyTorch 进行二分类任务时，可以利用线性模型（例如 逻辑回归 或 线性分类器）进行训练。\n",
    "\n",
    "这种模型在简单的分类任务中非常有效，尤其适用于线性可分的任务。\n",
    "\n",
    "下面是一个使用 PyTorch 实现简单线性分类模型的示例。\n",
    "\n",
    "## 使用 PyTorch 实现线性分类器\n",
    "\n",
    "假设我们有一个简单的二分类任务，输入特征为 X，标签为 y（例如，0 或 1）。\n",
    "\n",
    "### 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义线性模型\n",
    "\n",
    "我们可以使用 nn.Linear 来定义一个线性分类模型。对于二分类问题，我们只需要一个线性层和一个 sigmoid 激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        # 输入层 -> 线性层\n",
    "        self.linear = nn.Linear(input_dim, 1)  # 输出一个值（0 或 1）\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算线性层输出，然后通过 Sigmoid 激活函数\n",
    "        return torch.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建数据\n",
    "\n",
    "假设我们有一些简单的随机数据，特征为二维，标签为二分类（0 或 1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成一些示例数据\n",
    "X = torch.randn(100, 2)  # 100个样本，每个样本2个特征\n",
    "y = (X[:, 0] + X[:, 1] > 0).float().view(-1, 1)  # 生成标签，简单地根据两个特征的和来划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载\n",
    "\n",
    "将数据包装成 DataLoader 以便进行批量训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集和数据加载器\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 实例化模型\n",
    "model = LinearClassifier(input_dim=2)  # 输入特征维度为2\n",
    "\n",
    "# 损失函数：二元交叉熵损失\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 优化器：使用 Adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "\n",
    "进行训练，迭代数据集进行优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.586089164018631\n",
      "Epoch [20/100], Loss: 0.47466258704662323\n",
      "Epoch [30/100], Loss: 0.3786937817931175\n",
      "Epoch [40/100], Loss: 0.34872084856033325\n",
      "Epoch [50/100], Loss: 0.3288753107190132\n",
      "Epoch [60/100], Loss: 0.2915054261684418\n",
      "Epoch [70/100], Loss: 0.28621645644307137\n",
      "Epoch [80/100], Loss: 0.307458009570837\n",
      "Epoch [90/100], Loss: 0.25155021995306015\n",
      "Epoch [100/100], Loss: 0.2418215423822403\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)  # 输出概率\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()  # 清零梯度\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # 每10个epoch输出一次损失值\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估模型\n",
    "\n",
    "在训练完成后，我们可以在测试集或验证集上评估模型的表现。\n",
    "\n",
    "由于是二分类问题，我们通常会使用准确率作为评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.eval()  # 设置模型为评估模式\n",
    "with torch.no_grad():  # 在评估时不需要计算梯度\n",
    "    predicted = (model(X) > 0.5).float()  # 根据 sigmoid 输出进行阈值分类\n",
    "    accuracy = (predicted == y).float().mean()\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码总结\n",
    "\n",
    "上述代码展示了如何使用 PyTorch 实现一个简单的 线性分类模型：\n",
    "1. 线性分类器：通过 nn.Linear 定义了一个简单的线性分类器，输出一个单一值，通过 sigmoid 激活转换为概率。\n",
    "2.\t损失函数：使用了二元交叉熵损失 (BCELoss)，适用于二分类问题。\n",
    "3.\t优化器：使用了 Adam 优化器来更新模型参数。\n",
    "4.\t训练过程：通过循环训练数据集，更新模型参数以最小化损失函数。\n",
    "5.\t评估：根据预测的标签与真实标签比较，计算准确率。\n",
    "\n",
    "解释：\n",
    "1. 线性模型：即 y = wx + b，其中 w 是权重，x 是输入特征，b 是偏置。该模型学习线性边界，适用于线性可分问题。\n",
    "2. sigmoid 激活：用于将线性模型的输出映射到 0 和 1 之间，表示分类的概率。\n",
    "3. BCELoss：二元交叉熵损失，适用于二分类问题。\n",
    "\n",
    "扩展：\n",
    "\n",
    "如果是多分类问题，可以使用 Softmax 激活函数和 交叉熵损失，并且需要修改模型的输出层，使其输出多个类别的概率。\n",
    "\n",
    "结论：\n",
    "1. 线性模型是分类问题中一个简单但强大的工具，尤其适用于线性可分的任务。\n",
    "2. 使用 PyTorch 实现线性模型时，核心步骤包括：定义模型、选择损失函数、选择优化器、训练模型和评估模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
